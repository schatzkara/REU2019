Parameters:
Batch Size: 20
Tensor Size: (3,16,112,112)
Skip Length: 2
Precrop: True
Total Epochs: 1000
Learning Rate: 0.0001
Training...
	Batch 10/672 Loss:0.22214 con1:0.00118 con2:0.00123 recon1:0.10806 recon2:0.11167
	Batch 20/672 Loss:0.10920 con1:0.00064 con2:0.00065 recon1:0.05510 recon2:0.05281
	Batch 30/672 Loss:0.07674 con1:0.00087 con2:0.00085 recon1:0.03854 recon2:0.03647
	Batch 40/672 Loss:0.06270 con1:0.00059 con2:0.00059 recon1:0.03072 recon2:0.03081
	Batch 50/672 Loss:0.05034 con1:0.00050 con2:0.00049 recon1:0.02410 recon2:0.02525
	Batch 60/672 Loss:0.04731 con1:0.00031 con2:0.00031 recon1:0.02271 recon2:0.02398
	Batch 70/672 Loss:0.04450 con1:0.00023 con2:0.00023 recon1:0.02198 recon2:0.02205
	Batch 80/672 Loss:0.04139 con1:0.00022 con2:0.00022 recon1:0.02060 recon2:0.02035
	Batch 90/672 Loss:0.03403 con1:0.00021 con2:0.00021 recon1:0.01674 recon2:0.01689
	Batch 100/672 Loss:0.03361 con1:0.00016 con2:0.00015 recon1:0.01667 recon2:0.01664
	Batch 110/672 Loss:0.03110 con1:0.00012 con2:0.00012 recon1:0.01533 recon2:0.01554
	Batch 120/672 Loss:0.02702 con1:0.00011 con2:0.00011 recon1:0.01308 recon2:0.01372
	Batch 130/672 Loss:0.02869 con1:0.00009 con2:0.00009 recon1:0.01328 recon2:0.01522
	Batch 140/672 Loss:0.02778 con1:0.00008 con2:0.00008 recon1:0.01400 recon2:0.01362
	Batch 150/672 Loss:0.02876 con1:0.00007 con2:0.00007 recon1:0.01406 recon2:0.01455
	Batch 160/672 Loss:0.02583 con1:0.00006 con2:0.00006 recon1:0.01302 recon2:0.01269
	Batch 170/672 Loss:0.03286 con1:0.00006 con2:0.00006 recon1:0.01625 recon2:0.01649
	Batch 180/672 Loss:0.03036 con1:0.00006 con2:0.00006 recon1:0.01541 recon2:0.01482
	Batch 190/672 Loss:0.02340 con1:0.00006 con2:0.00006 recon1:0.01134 recon2:0.01193
	Batch 200/672 Loss:0.02497 con1:0.00006 con2:0.00006 recon1:0.01304 recon2:0.01181
	Batch 210/672 Loss:0.02223 con1:0.00006 con2:0.00006 recon1:0.01117 recon2:0.01095
	Batch 220/672 Loss:0.02550 con1:0.00005 con2:0.00005 recon1:0.01249 recon2:0.01290
	Batch 230/672 Loss:0.02253 con1:0.00005 con2:0.00005 recon1:0.01136 recon2:0.01108
	Batch 240/672 Loss:0.02411 con1:0.00005 con2:0.00005 recon1:0.01229 recon2:0.01172
	Batch 250/672 Loss:0.02321 con1:0.00004 con2:0.00004 recon1:0.01249 recon2:0.01064
	Batch 260/672 Loss:0.02295 con1:0.00004 con2:0.00004 recon1:0.01165 recon2:0.01122
	Batch 270/672 Loss:0.02394 con1:0.00004 con2:0.00004 recon1:0.01202 recon2:0.01184
	Batch 280/672 Loss:0.02176 con1:0.00003 con2:0.00004 recon1:0.01069 recon2:0.01100
	Batch 290/672 Loss:0.02143 con1:0.00004 con2:0.00004 recon1:0.01111 recon2:0.01025
	Batch 300/672 Loss:0.01994 con1:0.00003 con2:0.00003 recon1:0.00985 recon2:0.01003
	Batch 310/672 Loss:0.02159 con1:0.00003 con2:0.00003 recon1:0.01087 recon2:0.01065
	Batch 320/672 Loss:0.01958 con1:0.00003 con2:0.00003 recon1:0.00962 recon2:0.00989
	Batch 330/672 Loss:0.02050 con1:0.00003 con2:0.00003 recon1:0.01008 recon2:0.01035
	Batch 340/672 Loss:0.01962 con1:0.00003 con2:0.00003 recon1:0.00957 recon2:0.00999
	Batch 350/672 Loss:0.02036 con1:0.00003 con2:0.00003 recon1:0.00997 recon2:0.01034
	Batch 360/672 Loss:0.02015 con1:0.00003 con2:0.00003 recon1:0.01029 recon2:0.00981
	Batch 370/672 Loss:0.02156 con1:0.00003 con2:0.00003 recon1:0.01085 recon2:0.01065
	Batch 380/672 Loss:0.02119 con1:0.00003 con2:0.00003 recon1:0.01059 recon2:0.01055
	Batch 390/672 Loss:0.02058 con1:0.00003 con2:0.00003 recon1:0.01029 recon2:0.01023
	Batch 400/672 Loss:0.02527 con1:0.00002 con2:0.00003 recon1:0.01174 recon2:0.01348
	Batch 410/672 Loss:0.01961 con1:0.00003 con2:0.00003 recon1:0.00993 recon2:0.00963
	Batch 420/672 Loss:0.01760 con1:0.00002 con2:0.00002 recon1:0.00870 recon2:0.00886
	Batch 430/672 Loss:0.01696 con1:0.00002 con2:0.00002 recon1:0.00792 recon2:0.00899
	Batch 440/672 Loss:0.02084 con1:0.00002 con2:0.00002 recon1:0.01069 recon2:0.01010
	Batch 450/672 Loss:0.01676 con1:0.00002 con2:0.00002 recon1:0.00820 recon2:0.00852
	Batch 460/672 Loss:0.02122 con1:0.00002 con2:0.00002 recon1:0.01042 recon2:0.01075
	Batch 470/672 Loss:0.01864 con1:0.00002 con2:0.00002 recon1:0.00910 recon2:0.00950
	Batch 480/672 Loss:0.01953 con1:0.00002 con2:0.00002 recon1:0.00975 recon2:0.00973
	Batch 490/672 Loss:0.01659 con1:0.00002 con2:0.00002 recon1:0.00793 recon2:0.00862
	Batch 500/672 Loss:0.01938 con1:0.00002 con2:0.00002 recon1:0.00973 recon2:0.00961
	Batch 510/672 Loss:0.02136 con1:0.00002 con2:0.00002 recon1:0.01071 recon2:0.01061
	Batch 520/672 Loss:0.02001 con1:0.00002 con2:0.00002 recon1:0.00936 recon2:0.01061
	Batch 530/672 Loss:0.01703 con1:0.00002 con2:0.00002 recon1:0.00827 recon2:0.00871
	Batch 540/672 Loss:0.01957 con1:0.00002 con2:0.00002 recon1:0.00984 recon2:0.00969
	Batch 550/672 Loss:0.01778 con1:0.00002 con2:0.00002 recon1:0.00842 recon2:0.00932
	Batch 560/672 Loss:0.01892 con1:0.00002 con2:0.00002 recon1:0.00975 recon2:0.00913
	Batch 570/672 Loss:0.01808 con1:0.00002 con2:0.00002 recon1:0.00909 recon2:0.00895
	Batch 580/672 Loss:0.02252 con1:0.00002 con2:0.00002 recon1:0.01191 recon2:0.01057
	Batch 590/672 Loss:0.01919 con1:0.00002 con2:0.00002 recon1:0.00959 recon2:0.00956
	Batch 600/672 Loss:0.01919 con1:0.00002 con2:0.00002 recon1:0.00990 recon2:0.00926
	Batch 610/672 Loss:0.01755 con1:0.00002 con2:0.00002 recon1:0.00850 recon2:0.00901
	Batch 620/672 Loss:0.01801 con1:0.00002 con2:0.00002 recon1:0.00914 recon2:0.00883
	Batch 630/672 Loss:0.01591 con1:0.00002 con2:0.00002 recon1:0.00811 recon2:0.00776
	Batch 640/672 Loss:0.01943 con1:0.00002 con2:0.00002 recon1:0.00989 recon2:0.00951
	Batch 650/672 Loss:0.02007 con1:0.00002 con2:0.00002 recon1:0.01004 recon2:0.00999
	Batch 660/672 Loss:0.01806 con1:0.00002 con2:0.00002 recon1:0.00931 recon2:0.00871
	Batch 670/672 Loss:0.01673 con1:0.00002 con2:0.00002 recon1:0.00832 recon2:0.00838
Training Epoch 1/1000 Loss:0.03259 con1:0.00012 con2:0.00012 recon1:0.01614 recon2:0.01621
Validation...
	Batch 10/276 Loss:0.01350 con1:0.00001 con2: 0.00001 recon1:0.00668 recon2:0.00679
	Batch 20/276 Loss:0.01191 con1:0.00001 con2: 0.00001 recon1:0.00595 recon2:0.00593
	Batch 30/276 Loss:0.01394 con1:0.00001 con2: 0.00001 recon1:0.00688 recon2:0.00703
	Batch 40/276 Loss:0.02075 con1:0.00002 con2: 0.00002 recon1:0.01047 recon2:0.01024
	Batch 50/276 Loss:0.01428 con1:0.00001 con2: 0.00001 recon1:0.00725 recon2:0.00700
	Batch 60/276 Loss:0.01693 con1:0.00002 con2: 0.00002 recon1:0.00915 recon2:0.00775
	Batch 70/276 Loss:0.01646 con1:0.00002 con2: 0.00002 recon1:0.00844 recon2:0.00799
	Batch 80/276 Loss:0.01721 con1:0.00002 con2: 0.00001 recon1:0.00818 recon2:0.00900
	Batch 90/276 Loss:0.01118 con1:0.00001 con2: 0.00001 recon1:0.00562 recon2:0.00553
	Batch 100/276 Loss:0.01252 con1:0.00001 con2: 0.00001 recon1:0.00651 recon2:0.00598
	Batch 110/276 Loss:0.01090 con1:0.00001 con2: 0.00001 recon1:0.00544 recon2:0.00544
	Batch 120/276 Loss:0.01632 con1:0.00001 con2: 0.00001 recon1:0.00810 recon2:0.00819
	Batch 130/276 Loss:0.01594 con1:0.00002 con2: 0.00002 recon1:0.00793 recon2:0.00796
	Batch 140/276 Loss:0.02298 con1:0.00002 con2: 0.00002 recon1:0.01175 recon2:0.01120
	Batch 150/276 Loss:0.01628 con1:0.00002 con2: 0.00002 recon1:0.00807 recon2:0.00817
	Batch 160/276 Loss:0.02204 con1:0.00002 con2: 0.00002 recon1:0.01040 recon2:0.01160
	Batch 170/276 Loss:0.01863 con1:0.00002 con2: 0.00002 recon1:0.00871 recon2:0.00988
	Batch 180/276 Loss:0.01457 con1:0.00001 con2: 0.00001 recon1:0.00704 recon2:0.00750
	Batch 190/276 Loss:0.01236 con1:0.00001 con2: 0.00001 recon1:0.00583 recon2:0.00651
	Batch 200/276 Loss:0.01806 con1:0.00001 con2: 0.00002 recon1:0.00852 recon2:0.00951
	Batch 210/276 Loss:0.02009 con1:0.00002 con2: 0.00002 recon1:0.00997 recon2:0.01008
	Batch 220/276 Loss:0.01468 con1:0.00001 con2: 0.00001 recon1:0.00738 recon2:0.00727
	Batch 230/276 Loss:0.05255 con1:0.00003 con2: 0.00004 recon1:0.02536 recon2:0.02711
	Batch 240/276 Loss:0.01262 con1:0.00001 con2: 0.00001 recon1:0.00609 recon2:0.00650
	Batch 250/276 Loss:0.01299 con1:0.00001 con2: 0.00001 recon1:0.00645 recon2:0.00651
	Batch 260/276 Loss:0.01246 con1:0.00001 con2: 0.00001 recon1:0.00646 recon2:0.00596
	Batch 270/276 Loss:0.01589 con1:0.00001 con2: 0.00001 recon1:0.00799 recon2:0.00787
Validation Epoch 1/1000 Loss:0.01659 con1:0.00002 con2:0.00002 recon1:0.00826 recon2:0.00829
Training...
