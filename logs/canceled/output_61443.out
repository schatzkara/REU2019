Parameters:
Batch Size: 32
Tensor Size: (3,8,112,112)
Skip Length: 2
Precrop: False
Total Epochs: 1000
Learning Rate: 0.0001
FullNetwork(
  (vgg): VGG(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (6): ReLU(inplace)
      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (8): ReLU(inplace)
      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (11): ReLU(inplace)
      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (13): ReLU(inplace)
      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (15): ReLU(inplace)
      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (18): ReLU(inplace)
      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (20): ReLU(inplace)
      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (22): ReLU(inplace)
      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (25): ReLU(inplace)
      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (27): ReLU(inplace)
      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (29): ReLU(inplace)
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
    (classifier): Sequential(
      (0): Linear(in_features=25088, out_features=4096, bias=True)
      (1): ReLU(inplace)
      (2): Dropout(p=0.5)
      (3): Linear(in_features=4096, out_features=4096, bias=True)
      (4): ReLU(inplace)
      (5): Dropout(p=0.5)
      (6): Linear(in_features=4096, out_features=1000, bias=True)
    )
  )
  (i3d): InceptionI3d(
    (logits): Unit3D(
      (conv3d): Conv3d(1024, 157, kernel_size=[1, 1, 1], stride=(1, 1, 1))
    )
    (Conv3d_1a_7x7): Unit3D(
      (conv3d): Conv3d(3, 64, kernel_size=[7, 7, 7], stride=(2, 2, 2), bias=False)
      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
    )
    (MaxPool3d_2a_3x3): MaxPool3dSamePadding(kernel_size=[1, 3, 3], stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)
    (Conv3d_2b_1x1): Unit3D(
      (conv3d): Conv3d(64, 64, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
    )
    (Conv3d_2c_3x3): Unit3D(
      (conv3d): Conv3d(64, 192, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
      (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
    )
    (MaxPool3d_3a_3x3): MaxPool3dSamePadding(kernel_size=[1, 3, 3], stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)
    (Mixed_3b): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(192, 64, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(192, 96, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(96, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(192, 16, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(16, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(192, 32, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (Mixed_3c): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(256, 128, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(256, 128, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(128, 192, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(256, 32, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(32, 96, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (MaxPool3d_4a_3x3): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)
    (Mixed_4b): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(480, 192, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(480, 96, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(96, 208, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(208, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(480, 16, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(16, 48, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(480, 64, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (Mixed_4c): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(512, 160, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(512, 112, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(112, 224, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(512, 24, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(24, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(512, 64, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (Mixed_4d): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(128, 256, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(512, 24, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(24, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(512, 64, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (Mixed_4e): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(512, 112, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(512, 144, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(144, 288, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(512, 32, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(32, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(512, 64, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (Mixed_4f): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(528, 256, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(528, 160, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(160, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(320, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(528, 32, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(32, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(528, 128, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (MaxPool3d_5a_1x1): MaxPool3dSamePadding(kernel_size=[2, 2, 2], stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)
    (Mixed_5b): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(832, 256, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(832, 160, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(160, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(320, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(832, 32, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(32, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(832, 128, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (Mixed_5c): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(832, 384, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(832, 192, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(192, 384, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(832, 48, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(48, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(832, 128, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
  )
  (gen): Generator(
    (conv2d): Conv2d(1536, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (upsamp1): Upsample(scale_factor=2, mode=nearest)
    (conv3d_1a): Conv3d(1024, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
    (conv3d_1b): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
    (upsamp2): Upsample(scale_factor=2, mode=nearest)
    (conv3d_2a): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
    (conv3d_2b): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
    (upsamp3): Upsample(scale_factor=2, mode=nearest)
    (conv3d_3a): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
    (conv3d_3b): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
    (upsamp4): Upsample(scale_factor=2, mode=nearest)
    (conv3d_4): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
  )
)
Training...
	Batch 10/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 20/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 30/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 40/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 50/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 60/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 70/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 80/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 90/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 100/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 110/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 120/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 130/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 140/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 150/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 160/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 170/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 180/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 190/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 200/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 210/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 220/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 230/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 240/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 250/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 260/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 270/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 280/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 290/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 300/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 310/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 320/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 330/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 340/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 350/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 360/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 370/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 380/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 390/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 400/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 410/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 420/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Training Epoch 1/1000 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Validation...
	Batch 10/173 Loss:0.82143 con:0.31869 recon1:0.24841 recon2:0.25433
	Batch 20/173 Loss:0.83200 con:0.28683 recon1:0.27504 recon2:0.27013
	Batch 30/173 Loss:0.85317 con:0.30894 recon1:0.27719 recon2:0.26704
	Batch 40/173 Loss:0.87398 con:0.35278 recon1:0.26428 recon2:0.25692
	Batch 50/173 Loss:0.80188 con:0.29763 recon1:0.25653 recon2:0.24772
	Batch 60/173 Loss:0.87955 con:0.33668 recon1:0.26556 recon2:0.27730
	Batch 70/173 Loss:0.81233 con:0.29430 recon1:0.25591 recon2:0.26213
	Batch 80/173 Loss:0.87697 con:0.35316 recon1:0.26676 recon2:0.25706
	Batch 90/173 Loss:0.86012 con:0.33662 recon1:0.25677 recon2:0.26672
	Batch 100/173 Loss:0.88516 con:0.34482 recon1:0.26402 recon2:0.27632
	Batch 110/173 Loss:0.85772 con:0.30676 recon1:0.26944 recon2:0.28152
	Batch 120/173 Loss:0.84750 con:0.32344 recon1:0.26600 recon2:0.25806
	Batch 130/173 Loss:0.85596 con:0.29495 recon1:0.27145 recon2:0.28956
	Batch 140/173 Loss:0.83385 con:0.31245 recon1:0.26666 recon2:0.25474
	Batch 150/173 Loss:0.80480 con:0.28728 recon1:0.26595 recon2:0.25157
	Batch 160/173 Loss:0.82824 con:0.32112 recon1:0.25797 recon2:0.24915
	Batch 170/173 Loss:0.89759 con:0.33204 recon1:0.28045 recon2:0.28511
Validation Epoch 1/1000 Loss:0.84403 con:0.31265 recon1:0.26598 recon2:0.26541
Training...
	Batch 10/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 20/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 30/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 40/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 50/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 60/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 70/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 80/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 90/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 100/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 110/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 120/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 130/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 140/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 150/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 160/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 170/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 180/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 190/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 200/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 210/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 220/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 230/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 240/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 250/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 260/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 270/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 280/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 290/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 300/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 310/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 320/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 330/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 340/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 350/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 360/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 370/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 380/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 390/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 400/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 410/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 420/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Training Epoch 2/1000 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Validation...
	Batch 10/173 Loss:0.49209 con:0.32023 recon1:0.08648 recon2:0.08538
	Batch 20/173 Loss:0.45859 con:0.28836 recon1:0.08624 recon2:0.08398
	Batch 30/173 Loss:0.47899 con:0.31110 recon1:0.08539 recon2:0.08250
	Batch 40/173 Loss:0.52728 con:0.35495 recon1:0.08792 recon2:0.08442
	Batch 50/173 Loss:0.46267 con:0.29893 recon1:0.08259 recon2:0.08115
	Batch 60/173 Loss:0.50259 con:0.33864 recon1:0.07891 recon2:0.08504
	Batch 70/173 Loss:0.46140 con:0.29604 recon1:0.08214 recon2:0.08321
	Batch 80/173 Loss:0.52317 con:0.35556 recon1:0.08482 recon2:0.08279
	Batch 90/173 Loss:0.50956 con:0.33908 recon1:0.08490 recon2:0.08558
	Batch 100/173 Loss:0.52055 con:0.34650 recon1:0.08593 recon2:0.08812
	Batch 110/173 Loss:0.48021 con:0.30843 recon1:0.08628 recon2:0.08549
	Batch 120/173 Loss:0.49527 con:0.32561 recon1:0.08904 recon2:0.08062
	Batch 130/173 Loss:0.46861 con:0.29650 recon1:0.08438 recon2:0.08773
	Batch 140/173 Loss:0.48345 con:0.31436 recon1:0.08611 recon2:0.08298
	Batch 150/173 Loss:0.45768 con:0.28896 recon1:0.08627 recon2:0.08245
	Batch 160/173 Loss:0.48843 con:0.32249 recon1:0.08499 recon2:0.08096
	Batch 170/173 Loss:0.50792 con:0.33410 recon1:0.08693 recon2:0.08689
Validation Epoch 2/1000 Loss:0.48374 con:0.31448 recon1:0.08495 recon2:0.08431
Training...
	Batch 10/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 20/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 30/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 40/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 50/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 60/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 70/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 80/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 90/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 100/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 110/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 120/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 130/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 140/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 150/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 160/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 170/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 180/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 190/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 200/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 210/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 220/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 230/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 240/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 250/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 260/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 270/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 280/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 290/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 300/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 310/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 320/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 330/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 340/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 350/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 360/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 370/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 380/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 390/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 400/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 410/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 420/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Training Epoch 3/1000 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Validation...
	Batch 10/173 Loss:0.44282 con:0.32154 recon1:0.06066 recon2:0.06062
	Batch 20/173 Loss:0.40738 con:0.28966 recon1:0.05979 recon2:0.05793
	Batch 30/173 Loss:0.42700 con:0.31230 recon1:0.05956 recon2:0.05514
	Batch 40/173 Loss:0.47757 con:0.35675 recon1:0.05999 recon2:0.06083
	Batch 50/173 Loss:0.41996 con:0.30085 recon1:0.06114 recon2:0.05798
	Batch 60/173 Loss:0.45709 con:0.34061 recon1:0.05544 recon2:0.06105
	Batch 70/173 Loss:0.41315 con:0.29706 recon1:0.05802 recon2:0.05808
	Batch 80/173 Loss:0.47739 con:0.35672 recon1:0.05961 recon2:0.06106
	Batch 90/173 Loss:0.45954 con:0.34023 recon1:0.05993 recon2:0.05938
	Batch 100/173 Loss:0.46741 con:0.34827 recon1:0.05791 recon2:0.06123
	Batch 110/173 Loss:0.42593 con:0.31051 recon1:0.05796 recon2:0.05746
	Batch 120/173 Loss:0.44760 con:0.32766 recon1:0.06223 recon2:0.05771
	Batch 130/173 Loss:0.41357 con:0.29789 recon1:0.05648 recon2:0.05921
	Batch 140/173 Loss:0.43084 con:0.31593 recon1:0.05933 recon2:0.05558
	Batch 150/173 Loss:0.40408 con:0.29063 recon1:0.05774 recon2:0.05572
	Batch 160/173 Loss:0.44082 con:0.32396 recon1:0.05965 recon2:0.05720
	Batch 170/173 Loss:0.45377 con:0.33582 recon1:0.05743 recon2:0.06051
Validation Epoch 3/1000 Loss:0.43216 con:0.31606 recon1:0.05820 recon2:0.05791
Training...
	Batch 10/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 20/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 30/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 40/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 50/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 60/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 70/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 80/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 90/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 100/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 110/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 120/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 130/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 140/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 150/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 160/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 170/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 180/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 190/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 200/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 210/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 220/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 230/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 240/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 250/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 260/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 270/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 280/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 290/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 300/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 310/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 320/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 330/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 340/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 350/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 360/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 370/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 380/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 390/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 400/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 410/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 420/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Training Epoch 4/1000 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Validation...
	Batch 10/173 Loss:0.42760 con:0.31956 recon1:0.05418 recon2:0.05386
	Batch 20/173 Loss:0.39243 con:0.28773 recon1:0.05301 recon2:0.05169
	Batch 30/173 Loss:0.41178 con:0.31057 recon1:0.05256 recon2:0.04866
	Batch 40/173 Loss:0.46237 con:0.35424 recon1:0.05352 recon2:0.05461
	Batch 50/173 Loss:0.40496 con:0.29878 recon1:0.05484 recon2:0.05133
	Batch 60/173 Loss:0.44080 con:0.33842 recon1:0.04885 recon2:0.05354
	Batch 70/173 Loss:0.39867 con:0.29535 recon1:0.05155 recon2:0.05177
	Batch 80/173 Loss:0.46094 con:0.35399 recon1:0.05269 recon2:0.05426
	Batch 90/173 Loss:0.44398 con:0.33821 recon1:0.05300 recon2:0.05277
	Batch 100/173 Loss:0.45105 con:0.34566 recon1:0.05141 recon2:0.05397
	Batch 110/173 Loss:0.41003 con:0.30793 recon1:0.05119 recon2:0.05091
	Batch 120/173 Loss:0.43044 con:0.32476 recon1:0.05488 recon2:0.05080
	Batch 130/173 Loss:0.39823 con:0.29592 recon1:0.05034 recon2:0.05197
	Batch 140/173 Loss:0.41503 con:0.31353 recon1:0.05204 recon2:0.04946
	Batch 150/173 Loss:0.38852 con:0.28876 recon1:0.05041 recon2:0.04935
	Batch 160/173 Loss:0.42407 con:0.32195 recon1:0.05199 recon2:0.05013
	Batch 170/173 Loss:0.43806 con:0.33342 recon1:0.05106 recon2:0.05359
Validation Epoch 4/1000 Loss:0.41643 con:0.31387 recon1:0.05141 recon2:0.05115
Training...
	Batch 10/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 20/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 30/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 40/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 50/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 60/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 70/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 80/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 90/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 100/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 110/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 120/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 130/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 140/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 150/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 160/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 170/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 180/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 190/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 200/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 210/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 220/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 230/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 240/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 250/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 260/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 270/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 280/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 290/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 300/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 310/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 320/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 330/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 340/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 350/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 360/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 370/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 380/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 390/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 400/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 410/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 420/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Training Epoch 5/1000 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Validation...
	Batch 10/173 Loss:0.41625 con:0.31831 recon1:0.04922 recon2:0.04872
	Batch 20/173 Loss:0.38099 con:0.28682 recon1:0.04755 recon2:0.04662
	Batch 30/173 Loss:0.39923 con:0.30884 recon1:0.04679 recon2:0.04361
	Batch 40/173 Loss:0.45106 con:0.35266 recon1:0.04862 recon2:0.04978
	Batch 50/173 Loss:0.39335 con:0.29739 recon1:0.04966 recon2:0.04630
	Batch 60/173 Loss:0.42796 con:0.33654 recon1:0.04391 recon2:0.04751
	Batch 70/173 Loss:0.38681 con:0.29359 recon1:0.04644 recon2:0.04678
	Batch 80/173 Loss:0.44863 con:0.35224 recon1:0.04738 recon2:0.04902
	Batch 90/173 Loss:0.43154 con:0.33630 recon1:0.04759 recon2:0.04766
	Batch 100/173 Loss:0.43926 con:0.34460 recon1:0.04625 recon2:0.04841
	Batch 110/173 Loss:0.39843 con:0.30641 recon1:0.04611 recon2:0.04591
	Batch 120/173 Loss:0.41832 con:0.32360 recon1:0.04934 recon2:0.04538
	Batch 130/173 Loss:0.38681 con:0.29473 recon1:0.04557 recon2:0.04651
	Batch 140/173 Loss:0.40373 con:0.31250 recon1:0.04651 recon2:0.04472
	Batch 150/173 Loss:0.37659 con:0.28731 recon1:0.04480 recon2:0.04448
	Batch 160/173 Loss:0.41107 con:0.32029 recon1:0.04609 recon2:0.04469
	Batch 170/173 Loss:0.42593 con:0.33158 recon1:0.04615 recon2:0.04820
Validation Epoch 5/1000 Loss:0.40447 con:0.31238 recon1:0.04616 recon2:0.04594
Training...
	Batch 10/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 20/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 30/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 40/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 50/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 60/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 70/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 80/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 90/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 100/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 110/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 120/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 130/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 140/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 150/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 160/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 170/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 180/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 190/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 200/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 210/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 220/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 230/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 240/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 250/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 260/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 270/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 280/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 290/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 300/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 310/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 320/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 330/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 340/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 350/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 360/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 370/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 380/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 390/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 400/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 410/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 420/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Training Epoch 6/1000 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Validation...
	Batch 10/173 Loss:0.40854 con:0.31913 recon1:0.04494 recon2:0.04447
	Batch 20/173 Loss:0.37248 con:0.28736 recon1:0.04289 recon2:0.04224
	Batch 30/173 Loss:0.39078 con:0.30971 recon1:0.04170 recon2:0.03937
	Batch 40/173 Loss:0.44336 con:0.35345 recon1:0.04432 recon2:0.04559
	Batch 50/173 Loss:0.38585 con:0.29876 recon1:0.04508 recon2:0.04202
	Batch 60/173 Loss:0.41971 con:0.33762 recon1:0.03968 recon2:0.04242
	Batch 70/173 Loss:0.37887 con:0.29424 recon1:0.04218 recon2:0.04246
	Batch 80/173 Loss:0.44113 con:0.35336 recon1:0.04305 recon2:0.04472
	Batch 90/173 Loss:0.42338 con:0.33704 recon1:0.04308 recon2:0.04326
	Batch 100/173 Loss:0.43110 con:0.34559 recon1:0.04182 recon2:0.04370
	Batch 110/173 Loss:0.39032 con:0.30691 recon1:0.04185 recon2:0.04156
	Batch 120/173 Loss:0.40987 con:0.32425 recon1:0.04471 recon2:0.04091
	Batch 130/173 Loss:0.37884 con:0.29559 recon1:0.04133 recon2:0.04193
	Batch 140/173 Loss:0.39552 con:0.31295 recon1:0.04196 recon2:0.04061
	Batch 150/173 Loss:0.36913 con:0.28853 recon1:0.04028 recon2:0.04033
	Batch 160/173 Loss:0.40268 con:0.32119 recon1:0.04133 recon2:0.04016
	Batch 170/173 Loss:0.41785 con:0.33246 recon1:0.04194 recon2:0.04346
Validation Epoch 6/1000 Loss:0.39645 con:0.31316 recon1:0.04174 recon2:0.04155
Training...
	Batch 10/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 20/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 30/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 40/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 50/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 60/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 70/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 80/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 90/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 100/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 110/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 120/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 130/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 140/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 150/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 160/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 170/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 180/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 190/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 200/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 210/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 220/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 230/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 240/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 250/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 260/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 270/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 280/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 290/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 300/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 310/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 320/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 330/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 340/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 350/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 360/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 370/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 380/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 390/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 400/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 410/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 420/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Training Epoch 7/1000 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Validation...
	Batch 10/173 Loss:0.40236 con:0.31901 recon1:0.04194 recon2:0.04141
	Batch 20/173 Loss:0.36560 con:0.28734 recon1:0.03936 recon2:0.03890
	Batch 30/173 Loss:0.38366 con:0.30932 recon1:0.03803 recon2:0.03631
	Batch 40/173 Loss:0.43697 con:0.35315 recon1:0.04122 recon2:0.04260
	Batch 50/173 Loss:0.37844 con:0.29791 recon1:0.04163 recon2:0.03891
	Batch 60/173 Loss:0.41252 con:0.33702 recon1:0.03672 recon2:0.03878
	Batch 70/173 Loss:0.37295 con:0.29474 recon1:0.03901 recon2:0.03920
	Batch 80/173 Loss:0.43482 con:0.35336 recon1:0.03995 recon2:0.04151
	Batch 90/173 Loss:0.41714 con:0.33727 recon1:0.03975 recon2:0.04011
	Batch 100/173 Loss:0.42402 con:0.34528 recon1:0.03845 recon2:0.04029
	Batch 110/173 Loss:0.38454 con:0.30707 recon1:0.03883 recon2:0.03864
	Batch 120/173 Loss:0.40322 con:0.32416 recon1:0.04131 recon2:0.03775
	Batch 130/173 Loss:0.37235 con:0.29531 recon1:0.03831 recon2:0.03873
	Batch 140/173 Loss:0.38878 con:0.31265 recon1:0.03855 recon2:0.03759
	Batch 150/173 Loss:0.36215 con:0.28790 recon1:0.03708 recon2:0.03717
	Batch 160/173 Loss:0.39601 con:0.32128 recon1:0.03799 recon2:0.03674
	Batch 170/173 Loss:0.41171 con:0.33266 recon1:0.03899 recon2:0.04007
Validation Epoch 7/1000 Loss:0.38993 con:0.31303 recon1:0.03854 recon2:0.03837
Training...
	Batch 10/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 20/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 30/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 40/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 50/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 60/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 70/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 80/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 90/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 100/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 110/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 120/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 130/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 140/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 150/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 160/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 170/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 180/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 190/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 200/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 210/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 220/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 230/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 240/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 250/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 260/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 270/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 280/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 290/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 300/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 310/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 320/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 330/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 340/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 350/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 360/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 370/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 380/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 390/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 400/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 410/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 420/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Training Epoch 8/1000 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Validation...
	Batch 10/173 Loss:0.39826 con:0.31826 recon1:0.04032 recon2:0.03969
	Batch 20/173 Loss:0.36058 con:0.28649 recon1:0.03716 recon2:0.03693
	Batch 30/173 Loss:0.37991 con:0.30944 recon1:0.03583 recon2:0.03465
	Batch 40/173 Loss:0.43290 con:0.35274 recon1:0.03938 recon2:0.04078
	Batch 50/173 Loss:0.37445 con:0.29789 recon1:0.03949 recon2:0.03707
	Batch 60/173 Loss:0.40907 con:0.33735 recon1:0.03506 recon2:0.03666
	Batch 70/173 Loss:0.36823 con:0.29373 recon1:0.03724 recon2:0.03726
	Batch 80/173 Loss:0.43112 con:0.35334 recon1:0.03819 recon2:0.03959
	Batch 90/173 Loss:0.41326 con:0.33717 recon1:0.03788 recon2:0.03821
	Batch 100/173 Loss:0.41977 con:0.34507 recon1:0.03646 recon2:0.03824
	Batch 110/173 Loss:0.38113 con:0.30712 recon1:0.03707 recon2:0.03693
	Batch 120/173 Loss:0.40001 con:0.32479 recon1:0.03927 recon2:0.03595
	Batch 130/173 Loss:0.36860 con:0.29525 recon1:0.03650 recon2:0.03685
	Batch 140/173 Loss:0.38516 con:0.31280 recon1:0.03651 recon2:0.03585
	Batch 150/173 Loss:0.35844 con:0.28773 recon1:0.03536 recon2:0.03535
	Batch 160/173 Loss:0.39174 con:0.32087 recon1:0.03612 recon2:0.03475
	Batch 170/173 Loss:0.40839 con:0.33298 recon1:0.03729 recon2:0.03812
Validation Epoch 8/1000 Loss:0.38617 con:0.31296 recon1:0.03667 recon2:0.03653
Training...
	Batch 10/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 20/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 30/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 40/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 50/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 60/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 70/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 80/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 90/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 100/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 110/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 120/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 130/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 140/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 150/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 160/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 170/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 180/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 190/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 200/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 210/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 220/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 230/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 240/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 250/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 260/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 270/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 280/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 290/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 300/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 310/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 320/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 330/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 340/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 350/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 360/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 370/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 380/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 390/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 400/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 410/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
	Batch 420/420 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Training Epoch 9/1000 Loss:0.00000 con:0.00000 recon1:0.00000 recon2:0.00000
Validation...
	Batch 10/173 Loss:0.39726 con:0.31975 recon1:0.03910 recon2:0.03841
	Batch 20/173 Loss:0.35899 con:0.28802 recon1:0.03547 recon2:0.03550
	Batch 30/173 Loss:0.37798 con:0.31032 recon1:0.03424 recon2:0.03341
	Batch 40/173 Loss:0.43117 con:0.35400 recon1:0.03786 recon2:0.03931
	Batch 50/173 Loss:0.37236 con:0.29882 recon1:0.03790 recon2:0.03564
	Batch 60/173 Loss:0.40729 con:0.33834 recon1:0.03380 recon2:0.03514
	Batch 70/173 Loss:0.36702 con:0.29544 recon1:0.03586 recon2:0.03572
	Batch 80/173 Loss:0.42933 con:0.35439 recon1:0.03683 recon2:0.03810
	Batch 90/173 Loss:0.41133 con:0.33817 recon1:0.03647 recon2:0.03669
	Batch 100/173 Loss:0.41804 con:0.34642 recon1:0.03499 recon2:0.03663
	Batch 110/173 Loss:0.37993 con:0.30873 recon1:0.03567 recon2:0.03553
	Batch 120/173 Loss:0.39779 con:0.32542 recon1:0.03772 recon2:0.03465
	Batch 130/173 Loss:0.36661 con:0.29610 recon1:0.03510 recon2:0.03542
	Batch 140/173 Loss:0.38335 con:0.31390 recon1:0.03497 recon2:0.03448
	Batch 150/173 Loss:0.35686 con:0.28886 recon1:0.03410 recon2:0.03390
	Batch 160/173 Loss:0.39081 con:0.32277 recon1:0.03476 recon2:0.03328
	Batch 170/173 Loss:0.40630 con:0.33374 recon1:0.03594 recon2:0.03662
Validation Epoch 9/1000 Loss:0.38449 con:0.31412 recon1:0.03525 recon2:0.03512
Training...
slurmstepd: error: *** JOB 61443 ON c2-2 CANCELLED AT 2019-06-14T15:55:54 ***
